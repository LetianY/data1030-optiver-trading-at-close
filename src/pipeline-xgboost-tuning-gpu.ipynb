{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea897716",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-04T10:37:21.730839Z",
     "iopub.status.busy": "2023-12-04T10:37:21.730045Z",
     "iopub.status.idle": "2023-12-04T10:37:22.507152Z",
     "shell.execute_reply": "2023-12-04T10:37:22.506133Z"
    },
    "papermill": {
     "duration": 0.784314,
     "end_time": "2023-12-04T10:37:22.509377",
     "exception": false,
     "start_time": "2023-12-04T10:37:21.725063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/optiver-trading-at-the-close/public_timeseries_testing_util.py\n",
      "/kaggle/input/optiver-trading-at-the-close/train.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\n",
      "/kaggle/input/optiver-trading-at-the-close/optiver2023/competition.cpython-310-x86_64-linux-gnu.so\n",
      "/kaggle/input/optiver-trading-at-the-close/optiver2023/__init__.py\n",
      "/kaggle/input/data1030-optiver-trading-at-close/test_dataset.pkl\n",
      "/kaggle/input/data1030-optiver-trading-at-close/train_val_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import gc, time, warnings, joblib, pickle\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "from itertools import combinations\n",
    "from warnings import simplefilter\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b31dd3",
   "metadata": {
    "papermill": {
     "duration": 0.003247,
     "end_time": "2023-12-04T10:37:22.516340",
     "exception": false,
     "start_time": "2023-12-04T10:37:22.513093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11b3aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T10:37:22.524086Z",
     "iopub.status.busy": "2023-12-04T10:37:22.523723Z",
     "iopub.status.idle": "2023-12-04T10:37:23.552032Z",
     "shell.execute_reply": "2023-12-04T10:37:23.551310Z"
    },
    "papermill": {
     "duration": 1.034526,
     "end_time": "2023-12-04T10:37:23.554191",
     "exception": false,
     "start_time": "2023-12-04T10:37:22.519665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from mlxtend.evaluate.time_series import (\n",
    "    GroupTimeSeriesSplit,\n",
    "    plot_splits,\n",
    "    print_cv_info,\n",
    "    print_split_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89500c",
   "metadata": {
    "papermill": {
     "duration": 0.003184,
     "end_time": "2023-12-04T10:37:23.560982",
     "exception": false,
     "start_time": "2023-12-04T10:37:23.557798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8355b03e",
   "metadata": {
    "papermill": {
     "duration": 0.023844,
     "end_time": "2023-12-04T10:37:23.588180",
     "exception": false,
     "start_time": "2023-12-04T10:37:23.564336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gb_CV_MAE(X_other, y_other, groups_other,\n",
    "              X_test, y_test, groups_test,\n",
    "              preprocessor, model, param_grid, \n",
    "              path, model_name):\n",
    "    prep = Pipeline(steps=[('preprocessor', preprocessor)]) # for now we only preprocess, later we will add other steps here\n",
    "    \n",
    "    n_split = 4\n",
    "    count = 0\n",
    "    best_models = []\n",
    "    train_scores = np.zeros(n_split)\n",
    "    val_scores = np.zeros(n_split)\n",
    "    test_scores = np.zeros(n_split)\n",
    "    \n",
    "    # Split train-validation data: \n",
    "    len_group_other = groups_other.nunique()\n",
    "    gts = GroupTimeSeriesSplit(test_size=int(len_group_other*0.25), n_splits=n_split)\n",
    "    for i_train, i_val in gts.split(X_other, y_other, groups_other):\n",
    "        print(f'\\nFold {count+1} Parameter Searching:')\n",
    "        print(\"\\t Train index:\", i_train, \"Val index:\", i_val)\n",
    "        print(\"\\t Train size:\", len(i_train), \"Val size:\", len(i_val))\n",
    "        X_train, y_train, groups_train = X_other.iloc[i_train], y_other.iloc[i_train], groups_other.iloc[i_train]\n",
    "        X_val, y_val, groups_val = X_other.iloc[i_val], y_other.iloc[i_val], groups_other.iloc[i_val]\n",
    "        \n",
    "        X_train_preprocessed = prep.fit_transform(X_train)\n",
    "        X_val_preprocessed = prep.transform(X_val)\n",
    "        X_test_preprocessed  = prep.transform(X_test)\n",
    "        \n",
    "        feature_names = prep.get_feature_names_out()\n",
    "        \n",
    "        # Parameter Searching\n",
    "        pg = ParameterGrid(param_grid)\n",
    "        scores = np.zeros(len(pg))\n",
    "        \n",
    "        print(f'\\t Fitting {len(pg)} Parameters...')\n",
    "        for i in range(len(pg)):\n",
    "            params = pg[i]\n",
    "            model.set_params(**params)\n",
    "            eval_set = [(X_val_preprocessed, y_val)]\n",
    "            model.fit(X_train_preprocessed, y_train, \n",
    "                      eval_set=eval_set, early_stopping_rounds=50,verbose=False)\n",
    "            y_val_pred = model.predict(X_val_preprocessed)\n",
    "            scores[i] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "        best_params = np.array(pg)[scores == np.min(scores)]\n",
    "        \n",
    "        # apply the model with best parameter set\n",
    "        print('\\t Fitting Model with Best Parameter Set...')\n",
    "        model.set_params(**best_params[0])\n",
    "        model.fit(X_train_preprocessed, y_train,\n",
    "                  eval_set=eval_set, early_stopping_rounds=50, verbose=False)\n",
    "        best_models.append(model)\n",
    "        \n",
    "        # predict result\n",
    "        print('\\t Predicting Results...')\n",
    "        y_train_pred = model.predict(X_train_preprocessed)\n",
    "        y_val_pred = model.predict(X_val_preprocessed)\n",
    "        y_test_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "        # calculate the scores\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        \n",
    "        print('\\t Best Paramter:', best_params[0])\n",
    "        print('\\t Training MAE:', np.round(train_mae,4))\n",
    "        print('\\t Val MAE:', np.round(val_mae,4))\n",
    "        print('\\t Test MAE:', np.round(test_mae,4))\n",
    "        \n",
    "        # save results\n",
    "        train_scores[count] = train_mae\n",
    "        val_scores[count] = val_mae\n",
    "        test_scores[count] = test_mae\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    # summary report\n",
    "    scores_dict = {'Train_Scores': train_scores, \n",
    "                   'Val_Scores': val_scores, \n",
    "                   'Test_Scores': test_scores}\n",
    "    print(scores_dict)\n",
    "    print('test mean:', np.mean(test_scores))\n",
    "    print('test std:', np.std(test_scores))\n",
    "    \n",
    "    # save train and test scores\n",
    "    with open(os.path.join(path, f'{model_name}_scores.pkl'), 'wb') as file:\n",
    "        pickle.dump(scores_dict, file)\n",
    "    with open(os.path.join(path, f'{model_name}_best_models.pkl'), 'wb') as file:\n",
    "        pickle.dump(best_models, file)\n",
    "        \n",
    "    # Free up memory by deleting fold-specific variables\n",
    "    del X_train, X_train_preprocessed, y_train, groups_train\n",
    "    del X_val, X_val_preprocessed, y_val, groups_val\n",
    "    gc.collect()\n",
    " \n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe7c71",
   "metadata": {
    "papermill": {
     "duration": 0.003119,
     "end_time": "2023-12-04T10:37:23.594752",
     "exception": false,
     "start_time": "2023-12-04T10:37:23.591633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c141fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T10:37:23.602532Z",
     "iopub.status.busy": "2023-12-04T10:37:23.602296Z",
     "iopub.status.idle": "2023-12-04T10:37:28.383650Z",
     "shell.execute_reply": "2023-12-04T10:37:28.382795Z"
    },
    "papermill": {
     "duration": 4.787959,
     "end_time": "2023-12-04T10:37:28.385966",
     "exception": false,
     "start_time": "2023-12-04T10:37:23.598007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_folder = '/kaggle/input/data1030-optiver-trading-at-close/'\n",
    "# data_folder = '../data/preprocessed/'\n",
    "\n",
    "with open(os.path.join(data_folder, 'train_val_dataset.pkl'), 'rb') as file:\n",
    "    train_val_dataset = pickle.load(file)\n",
    "    \n",
    "with open(os.path.join(data_folder, 'test_dataset.pkl'), 'rb') as file:\n",
    "    test_dataset = pickle.load(file)\n",
    "\n",
    "X_other, y_other, groups_other = train_val_dataset['X_other'], train_val_dataset['y_other'], train_val_dataset['groups_other']\n",
    "X_test, y_test, groups_test, submission_id = test_dataset['X_test'], test_dataset['y_test'], test_dataset['groups_test'], test_dataset['submission_id']\n",
    "\n",
    "# collect which encoder to use on each feature\n",
    "onehot_ftrs = ['imbalance_buy_sell_flag', 'stock_id']\n",
    "std_ftrs = ['seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size', \n",
    "            'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', \n",
    "            'wap', 'lagged_target_1d_0', 'lagged_target_1d_10', 'lagged_target_1d_20', \n",
    "            'lagged_target_1d_30', 'lagged_target_1d_40', 'lagged_target_1d_50', \n",
    "            'lagged_target_1d_60', 'lagged_target_1d_70', 'lagged_target_1d_80', \n",
    "            'lagged_target_1d_90', 'lagged_target_1d_100', 'lagged_target_1d_110', \n",
    "            'lagged_target_1d_120', 'lagged_target_1d_130', 'lagged_target_1d_140', \n",
    "            'lagged_target_1d_150', 'lagged_target_1d_160', 'lagged_target_1d_170', \n",
    "            'lagged_target_1d_180', 'lagged_target_1d_190', 'lagged_target_1d_200', \n",
    "            'lagged_target_1d_210', 'lagged_target_1d_220', 'lagged_target_1d_230', \n",
    "            'lagged_target_1d_240', 'lagged_target_1d_250', 'lagged_target_1d_260', \n",
    "            'lagged_target_1d_270', 'lagged_target_1d_280', 'lagged_target_1d_290', \n",
    "            'lagged_target_1d_300', 'lagged_target_1d_310', 'lagged_target_1d_320', \n",
    "            'lagged_target_1d_330', 'lagged_target_1d_340', 'lagged_target_1d_350', \n",
    "            'lagged_target_1d_360', 'lagged_target_1d_370', 'lagged_target_1d_380', \n",
    "            'lagged_target_1d_390', 'lagged_target_1d_400', 'lagged_target_1d_410', \n",
    "            'lagged_target_1d_420', 'lagged_target_1d_430', 'lagged_target_1d_440', \n",
    "            'lagged_target_1d_450', 'lagged_target_1d_460', 'lagged_target_1d_470', \n",
    "            'lagged_target_1d_480', 'lagged_target_1d_490', 'lagged_target_1d_500', \n",
    "            'lagged_target_1d_510', 'lagged_target_1d_520', 'lagged_target_1d_530', \n",
    "            'lagged_target_1d_540', 'volume', 'mid_price', 'liquidity_imbalance', \n",
    "            'matched_imbalance', 'size_imbalance', 'reference_price_far_price_imb', \n",
    "            'reference_price_near_price_imb', 'reference_price_ask_price_imb', \n",
    "            'reference_price_bid_price_imb', 'reference_price_wap_imb', 'far_price_near_price_imb', \n",
    "            'far_price_ask_price_imb', 'far_price_bid_price_imb', 'far_price_wap_imb', \n",
    "            'near_price_ask_price_imb', 'near_price_bid_price_imb', 'near_price_wap_imb', \n",
    "            'ask_price_bid_price_imb', 'ask_price_wap_imb', 'bid_price_wap_imb', 'price_spread', \n",
    "            'price_pressure', 'market_urgency', 'depth_pressure', 'all_prices_mean', \n",
    "            'all_sizes_mean', 'all_prices_std', 'all_sizes_std', 'all_prices_skew', \n",
    "            'all_sizes_skew', 'all_prices_kurt', 'all_sizes_kurt', 'dow', 'seconds', 'minute']\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "model_save_path = 'result' \n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "\n",
    "result_path = '/kaggle/working/result/'\n",
    "# result_path = '../result/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8fb5e",
   "metadata": {
    "papermill": {
     "duration": 0.003398,
     "end_time": "2023-12-04T10:37:28.393146",
     "exception": false,
     "start_time": "2023-12-04T10:37:28.389748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a087cf39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T10:37:28.401160Z",
     "iopub.status.busy": "2023-12-04T10:37:28.400837Z",
     "iopub.status.idle": "2023-12-04T14:54:52.513842Z",
     "shell.execute_reply": "2023-12-04T14:54:52.512956Z"
    },
    "papermill": {
     "duration": 15444.119543,
     "end_time": "2023-12-04T14:54:52.516071",
     "exception": false,
     "start_time": "2023-12-04T10:37:28.396528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 Parameter Searching:\n",
      "\t Train index: [     0      1      2 ... 743181 743182 743183] Val index: [ 743184  743185  743186 ... 1002231 1002232 1002233]\n",
      "\t Train size: 743184 Val size: 259050\n",
      "\t Fitting 80 Parameters...\n",
      "\t Fitting Model with Best Parameter Set...\n",
      "\t Predicting Results...\n",
      "\t Best Paramter: {'colsample_bytree': 0.9, 'eval_metric': 'mae', 'learning_rate': 0.01, 'max_depth': 3, 'missing': nan, 'n_estimators': 6000, 'n_thread': -1, 'reg_alpha': 0.1, 'reg_lambda': 2, 'seed': 42, 'subsample': 0.66, 'tree_method': 'gpu_hist', 'verbosity': 0}\n",
      "\t Training MAE: 5.2573\n",
      "\t Val MAE: 6.5528\n",
      "\t Test MAE: 6.7388\n",
      "\n",
      "Fold 2 Parameter Searching:\n",
      "\t Train index: [ 10505  10506  10507 ... 753961 753962 753963] Val index: [ 753964  753965  753966 ... 1013066 1013067 1013068]\n",
      "\t Train size: 743459 Val size: 259105\n",
      "\t Fitting 80 Parameters...\n",
      "\t Fitting Model with Best Parameter Set...\n",
      "\t Predicting Results...\n",
      "\t Best Paramter: {'colsample_bytree': 0.9, 'eval_metric': 'mae', 'learning_rate': 0.01, 'max_depth': 1, 'missing': nan, 'n_estimators': 6000, 'n_thread': -1, 'reg_alpha': 1, 'reg_lambda': 2, 'seed': 42, 'subsample': 0.66, 'tree_method': 'gpu_hist', 'verbosity': 0}\n",
      "\t Training MAE: 5.2761\n",
      "\t Val MAE: 6.6611\n",
      "\t Test MAE: 6.7423\n",
      "\n",
      "Fold 3 Parameter Searching:\n",
      "\t Train index: [ 21010  21011  21012 ... 764741 764742 764743] Val index: [ 764744  764745  764746 ... 1023901 1023902 1023903]\n",
      "\t Train size: 743734 Val size: 259160\n",
      "\t Fitting 80 Parameters...\n",
      "\t Fitting Model with Best Parameter Set...\n",
      "\t Predicting Results...\n",
      "\t Best Paramter: {'colsample_bytree': 0.9, 'eval_metric': 'mae', 'learning_rate': 0.01, 'max_depth': 1, 'missing': nan, 'n_estimators': 6000, 'n_thread': -1, 'reg_alpha': 0.1, 'reg_lambda': 1, 'seed': 42, 'subsample': 0.66, 'tree_method': 'gpu_hist', 'verbosity': 0}\n",
      "\t Training MAE: 5.2857\n",
      "\t Val MAE: 6.7285\n",
      "\t Test MAE: 6.7413\n",
      "\n",
      "Fold 4 Parameter Searching:\n",
      "\t Train index: [ 31515  31516  31517 ... 775521 775522 775523] Val index: [ 775524  775525  775526 ... 1034736 1034737 1034738]\n",
      "\t Train size: 744009 Val size: 259215\n",
      "\t Fitting 80 Parameters...\n",
      "\t Fitting Model with Best Parameter Set...\n",
      "\t Predicting Results...\n",
      "\t Best Paramter: {'colsample_bytree': 0.9, 'eval_metric': 'mae', 'learning_rate': 0.01, 'max_depth': 7, 'missing': nan, 'n_estimators': 6000, 'n_thread': -1, 'reg_alpha': 1, 'reg_lambda': 2, 'seed': 42, 'subsample': 0.66, 'tree_method': 'gpu_hist', 'verbosity': 0}\n",
      "\t Training MAE: 5.2275\n",
      "\t Val MAE: 7.0589\n",
      "\t Test MAE: 6.7407\n",
      "{'Train_Scores': array([5.25728998, 5.276145  , 5.28572996, 5.22754331]), 'Val_Scores': array([6.552755  , 6.66106007, 6.72846395, 7.05888786]), 'Test_Scores': array([6.73876265, 6.74234162, 6.74128729, 6.74073149])}\n",
      "test mean: 6.740780763151302\n",
      "test std: 0.0013007745099942825\n",
      "XGB Running time: 15444.105332136154\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"learning_rate\": [0.01],\n",
    "              \"n_estimators\": [6000],\n",
    "              'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "              'reg_lambda': [0.1, 0.5, 1, 2],\n",
    "              \"missing\": [np.nan], \n",
    "              \"max_depth\": [1, 3, 7, 11, 13],\n",
    "              \"colsample_bytree\": [0.9],              \n",
    "              \"subsample\": [0.66],\n",
    "              \"eval_metric\": ['mae'],\n",
    "              \"seed\": [42],\n",
    "              \"n_thread\": [-1],\n",
    "              \"tree_method\": ['gpu_hist'],\n",
    "              \"verbosity\": [0]\n",
    "             }\n",
    "model = XGBRegressor()\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_best_models = gb_CV_MAE(X_other, y_other, groups_other,\n",
    "                            X_test, y_test, groups_test,\n",
    "                            preprocessor, model, param_grid, \n",
    "                            result_path, 'xgboost')\n",
    "print('XGB Running time:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f09b44",
   "metadata": {
    "papermill": {
     "duration": 0.004667,
     "end_time": "2023-12-04T14:54:52.525721",
     "exception": false,
     "start_time": "2023-12-04T14:54:52.521054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    },
    {
     "datasetId": 4103751,
     "sourceId": 7118588,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15454.639127,
   "end_time": "2023-12-04T14:54:53.079204",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-04T10:37:18.440077",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
